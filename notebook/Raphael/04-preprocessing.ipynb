{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os, pathlib, sys, re, string, spacy, bs4, bs4apache_beam as beam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "workingdir=os.getcwd()\n",
    "d=[d for d in os.listdir(workingdir)]\n",
    "n=0\n",
    "while not set(['notebook']).issubset(set(d)):\n",
    "    workingdir=str(pathlib.Path(workingdir).parents[0])\n",
    "\n",
    "    d=[d for d in os.listdir(str(workingdir))]\n",
    "    n+=1\n",
    "    if n>5:\n",
    "        break\n",
    "sys.path.insert(0, workingdir)\n",
    "os.chdir(workingdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Configuring spaCy for NLP Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Apache Beam and GCP Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pipeline_options = beam.options.pipeline_options.PipelineOptions()\n",
    "gcp_options = beam.options.pipeline_options.GoogleCloudOptions\n",
    "standard_options = beam.options.pipeline_options.StandardOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "google_cloud_options = pipeline_options.view_as(gcp_options)\n",
    "google_cloud_options.project = 'axa-ch-machine-learning-dev'\n",
    "google_cloud_options.job_name = 'nlp_text_classification_preprocessing'\n",
    "google_cloud_options.staging_location = 'gs://nlp_text_classification'\n",
    "google_cloud_options.temp_location = 'gs://nlp_text_classification'\n",
    "pipeline_options.view_as(standard_options).runner = 'DataflowRunner'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Creating a DoFn Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class Split(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        self.id, self.title, self.body, self.tags = element.split(\",\")\n",
    "\n",
    "        return [{\n",
    "            'id': self.id,\n",
    "            'title': self.title,\n",
    "            'body': self.body,\n",
    "            'tags': self.tags\n",
    "        }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class CleanText(beam.DoFn):\n",
    "    def __init__(self):\n",
    "        self.spacy = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "        \n",
    "    def __decode_html(self, input_str: str) -> str:\n",
    "        self.soup = bs4.BeautifulSoup(input_str, 'html.parser')\n",
    "        self.output = self.soup.text\n",
    "        return self.output\n",
    "\n",
    "    def __nlp(self, input_str: str) -> list:\n",
    "        self.doc = self.spacy(input_str)\n",
    "        self.stopwords = list(string.punctuation + string.digits) + ['-pron-']\n",
    "        self.output = [token.lemma_.lower() for token in self.doc if not token.is_stop \n",
    "                  and token.lemma_.lower() not in self.stopwords]\n",
    "        return self.output\n",
    "\n",
    "    def __split_tags(self, tags: str) -> list:\n",
    "        return tags.split('|')\n",
    "\n",
    "    def process(self, element):\n",
    "        self.title_array = self.__nlp(element['title'])\n",
    "        self.body_decoded = self.__decode_html(element['tags'])\n",
    "        self.body_array = self.__nlp(self.body_decoded)\n",
    "        self.tag_array = self.__split_tags(element['tags'])\n",
    "        \n",
    "        return [{'id': int(element['id']), \n",
    "                 'title': self.title_array, \n",
    "                 'body': self.body_array, \n",
    "                 'tags': self.tag_array}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Local Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "local_file = 'data/beam_test.csv'\n",
    "if os.path.exists('data/beam_output.txt'):\n",
    "    os.remove('data/beam_output.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "with beam.Pipeline(argv=sys.argv) as p:\n",
    "    file = p                  | \"ReadLocalFile\" >> beam.io.ReadFromText(local_file)\n",
    "    table = file              | \"CreateDictionary\"  >> beam.ParDo(Split())\n",
    "    clean_text = table        | \"ProcessFields\" >> beam.ParDo(CleanText())\n",
    "    clean_text                | \"WriteLocalFile\" >> beam.io.WriteToText('data/beam_output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## GCP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "query = '''SELECT\n",
    "  id,\n",
    "  title,\n",
    "  body,\n",
    "  tags\n",
    "FROM\n",
    "  bigquery-public-data:stackoverflow.stackoverflow_posts'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "table_schema = {'fields': [\n",
    "    {'name': 'id', 'type': 'NUMERIC', 'mode': 'REQUIRED'},\n",
    "    {'name': 'title', 'type': 'ARRAY', 'mode': 'NULLABLE'},\n",
    "    {'name': 'body', 'type': 'ARRAY', 'mode': 'NULLABLE'},\n",
    "    {'name': 'tags', 'type': 'ARRAY', 'mode': 'NULLABLE'},\n",
    "]}\n",
    "new_table = 'nlp_text_classification.stackoverflow_posts_preprocessed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "with beam.Pipeline(options=pipeline_options) as p:\n",
    "    table = p                 | \"QueryTable\" >> beam.io.Read(beam.io.BigQuerySource(query))\n",
    "    clean_text = table        | \"ProcessFields\" >> beam.ParDo(CleanText())\n",
    "    clean_text                | \"WriteTable\" >> beam.io.WriteToBigQuery(\n",
    "                                                    new_table,\n",
    "                                                    schema=table_schema,\n",
    "                                                    write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE,\n",
    "                                                    create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-env_nlp_text_class]",
   "language": "python",
   "name": "conda-env-.conda-env_nlp_text_class-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
