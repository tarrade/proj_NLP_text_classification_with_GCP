{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "post_2 = '''<p>I have an <strong>Edit</strong> button in my header. And I populating my <strong>TableLayout</strong> in a loop. In The loop I am inflating a <strong>Delete</strong> button.<br> Following is the code I have used : </p> <p><strong>MainActivity</strong> : </p> <pre><code>@Override public void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.cookbooklist); btnHeaderEdit = (Button)findViewById(R.id.btnEdit); btnHeaderEdit.setVisibility(View.VISIBLE); delete_button = (View)findViewById(R.id.btnDelete); listTable = (TableLayout)findViewById(R.id.cookbookListTable); btnHeaderEdit.setOnClickListener(new OnClickListener() { @Override public void onClick(View v) { // TODO Auto-generated method stub delete_button.getTag(); delete_button.setVisibility(View.VISIBLE); } }); for(int i=0;i&lt;=10;i++) { // Row to display news title final TableRow newsRow = new TableRow(this); newsRow.setMinimumHeight(200); newsRow.setClickable(true); newsRow.setTag(i); newsRow.setBackgroundColor(Color.WHITE); // Some other views //create inflater LayoutInflater inflater = getLayoutInflater(); delete_button = inflater.inflate(R.layout.deletebutton (ViewGroup) newsRow false); delete_button.setTag(i); delete_button.setOnClickListener(new OnClickListener() { @Override public void onClick(View v) { // TODO Auto-generated method stub listTable.removeView(newsRow); } }); //Add views in table newsRow.addView(delete_button); listTable.addView(newsRow); } } </code></pre> <p><strong>delebutton.xml</strong> : </p> <pre><code>&lt;Button xmlns:android= http://schemas.android.com/apk/res/android android:id= @+id/btnDelete android:layout_width= 100dip android:visibility= invisible android:layout_height= 40dip android:padding= 10sp android:text= Delete &gt; &lt;/Button&gt; </code></pre> <p><strong>Question</strong> : </p> <p>The problem I am facing is that when I click the <strong>Edit</strong> button in header <strong>Delete</strong> button appears only in the last row. When I setVisibility of <strong>Delete</strong> button to Visible in layout it appears in all rows. But I want it to be invisible in the start. And on clicking the <strong>Edit</strong> button it should appear in all rows. I Am wondering how to achieve that.<br> Can someone assist me? Let me know if more code is needed.</p> <p>Thanks The problem I am facing is that when</p>'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os, pathlib, sys, re, string, spacy, bs4, apache_beam as beam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Configuring spaCy for NLP Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /home/.conda-env/env_nlp_text_class/lib/python3.6/site-packages (2.1.0)\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "post_1 = '''<p>I'm trying to substitute something in a string in python and am having some \n",
    "trouble. Here's what I'd like to do.</p> <p>For a given comment in my posting:</p> \n",
    "<pre><code> here are some great sites that i will do cool things with! \n",
    "http://stackoverflow.com/it's a pig &amp; http://google.com </code></pre> <p>I'd like to use \n",
    "python to make the strings like this:</p> <pre><code> here are some great sites that i will do \n",
    "cool things with! &lt;a href= http://stackoverflow.com &gt;http%3A//stackoverflow.com&lt;/a&gt; \n",
    "&amp;amp; &lt;a href= http://google.com &gt;http%3A//google.com&lt;/a&gt; </code></pre> \n",
    "<p>Here's what I have so far...</p> <pre><code>import re import urllib def getExpandedURL(url) \n",
    "encoded_url = urllib.quote(url) return &lt;a href=\\ &lt;a href= +url+ \\ &gt; \n",
    "+encoded_url+ &lt;/a&gt; text = '&lt;text from above&gt;' url_pattern = \n",
    "re.compile('(http.+?[^ ]+' re.I | re.S | re.M) url_iterator = url_pattern.finditer(text) \n",
    "for matched_url in url_iterator: getExpandedURL(matched_url.groups(1)[0]) </code></pre> \n",
    "<p>But this is where i'm stuck. I've previously seen things on here like this: \n",
    "<a href= http://stackoverflow.com/questions/140182/regular-expressions-but-for-writing-in-the-match#142188 >\n",
    "Regular Expressions but for Writing in the Match</a> but surely there's got to be a \n",
    "better way than iterating through each match and doing a position replace on them. \n",
    "The difficulty here is that it's not a straight replace but I need to do something \n",
    "specific with each match before replacing it.</p>'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def clean_text(input_str:str) ->str:\n",
    "        \n",
    "    def decode_html(input_str: str) -> str:\n",
    "        soup = bs4.BeautifulSoup(input_str, 'html.parser')\n",
    "        text_soup = soup.find_all('p')\n",
    "        code_soup = soup.find_all('code')\n",
    "        text = []\n",
    "        code = []\n",
    "        \n",
    "        for temp_text in text_soup:\n",
    "            text.append(temp_text.text)\n",
    "            \n",
    "        for temp_code in code_soup:\n",
    "            code.append(temp_code.text)\n",
    "        \n",
    "        return ' '.join(text), ' '.join(code)\n",
    "    \n",
    "    def remove_url(input_str: str) ->str:\n",
    "        return re.sub('http\\S+', '', input_str)\n",
    "    \n",
    "    def remove_punctuation(input_str):\n",
    "        return re.sub('''[!\"#$%&\\\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\s]+''', ' ', input_str)\n",
    "\n",
    "    def advanced_nlp(input_str: str) -> list:\n",
    "        spacy_obj = spacy.load('en_core_web_sm')\n",
    "        doc = spacy_obj(input_str)\n",
    "        \n",
    "        stopwords = list(string.digits) + ['-pron-']\n",
    "        \n",
    "        output = [token.lemma_.lower() for token in doc if not token.is_stop \n",
    "                  and token.lemma_.lower() not in stopwords and len(token.lemma_.lower()) > 1]\n",
    "        return ' '.join(output)\n",
    "\n",
    "    text, code = decode_html(input_str)\n",
    "    \n",
    "    text = remove_url(text)\n",
    "    text = remove_url(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = advanced_nlp(text)\n",
    "    \n",
    "    code = remove_url(code)\n",
    "    code = remove_url(code)\n",
    "    code = remove_punctuation(code)\n",
    "    code = advanced_nlp(code)\n",
    "        \n",
    "    return text, code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' p I m trying to substitute something in a string in python and am having some trouble  Here s what I d like to do p   p For a given comment in my posting p   pre code  here are some great sites that i will do cool things with  http stackoverflow com it s a pig  amp  http google com  code pre   p I d like to use python to make the strings like this p   pre code  here are some great sites that i will do cool things with   lt a href  http stackoverflow com  gt http 3A stackoverflow com lt a gt   amp amp   lt a href  http google com  gt http 3A google com lt a gt   code pre   p Here s what I have so far p   pre code import re import urllib def getExpandedURL url  encoded url   urllib quote url  return  lt a href \\\\  lt a href   url  \\\\  gt   encoded url   lt a gt  text    lt text from above gt  url pattern   re compile http    re I   re S   re M  url iterator   url pattern finditer text  for matched url in url iterator  getExpandedURL matched url groups 1 0   code pre   p But this is where i m stuck  I ve previously seen things on here like this   a href  http stackoverflow com questions 140182 regular expressions but for writing in the match 142188  Regular Expressions but for Writing in the Match a  but surely there s got to be a better way than iterating through each match and doing a position replace on them  The difficulty here is that it s not a straight replace but I need to do something specific with each match before replacing it p '"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('''[!\"#$%&\\+'()*+,-./:;<=>?@[\\\\]^_`{|}~]+''', ' ', post_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "text, code = clean_text(post_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'great site cool thing pig great site cool thing href amp href import import urllib def getexpandedurl url encode url urllib quote url return href href url encode url text text url pattern compile url iterator url pattern finditer text match url url iterator getexpandedurl match url group'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Local Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "local_file = 'data/beam_test.csv'\n",
    "if os.path.exists('data/beam_output.txt'):\n",
    "    os.remove('data/beam_output.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "with beam.Pipeline(argv=sys.argv) as p:\n",
    "    file = p                  | \"ReadLocalFile\" >> beam.io.ReadFromText(local_file)\n",
    "    table = file              | \"CreateDictionary\"  >> beam.ParDo(Split())\n",
    "    clean_text = table        | \"ProcessFields\" >> beam.ParDo(CleanText())\n",
    "    clean_text                | \"WriteLocalFile\" >> beam.io.WriteToText('data/beam_output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## GCP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "query = '''SELECT\n",
    "  id,\n",
    "  title,\n",
    "  body,\n",
    "  tags\n",
    "FROM\n",
    "  `nlp-text-classification.stackoverflow.posts_p1_subset`'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "table_schema = {'fields': [\n",
    "    {'name': 'id', 'type': 'INTEGER', 'mode': 'NULLABLE'},\n",
    "    {'name': 'title', 'type': 'STRING', 'mode': 'NULLABLE'},\n",
    "    {'name': 'body', 'type': 'STRING', 'mode': 'NULLABLE'},\n",
    "    {'name': 'tags', 'type': 'STRING', 'mode': 'REPEATED'},\n",
    "]}\n",
    "new_table = beam.io.gcp.internal.clients.bigquery.TableReference(\n",
    "    projectId='nlp-text-classification',\n",
    "    datasetId='stackoverflow',\n",
    "    tableId='posts_p2_subset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-c1e88fc6-ed60-4317-97db-97d53e88cf61.json']\n",
      "WARNING:root:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-c1e88fc6-ed60-4317-97db-97d53e88cf61.json']\n"
     ]
    },
    {
     "ename": "DataflowRuntimeException",
     "evalue": "Dataflow pipeline failed. State: FAILED, Error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/apache_beam/internal/pickler.py\", line 261, in loads\n    return dill.loads(s)\n  File \"/usr/local/lib/python3.6/site-packages/dill/_dill.py\", line 317, in loads\n    return load(file, ignore)\n  File \"/usr/local/lib/python3.6/site-packages/dill/_dill.py\", line 305, in load\n    obj = pik.load()\n  File \"/usr/local/lib/python3.6/site-packages/dill/_dill.py\", line 577, in _load_type\n    return _reverse_typemap[name]\nKeyError: 'ClassType'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/dataflow_worker/batchworker.py\", line 649, in do_work\n    work_executor.execute()\n  File \"/usr/local/lib/python3.6/site-packages/dataflow_worker/executor.py\", line 176, in execute\n    op.start()\n  File \"apache_beam/runners/worker/operations.py\", line 587, in apache_beam.runners.worker.operations.DoOperation.start\n  File \"apache_beam/runners/worker/operations.py\", line 588, in apache_beam.runners.worker.operations.DoOperation.start\n  File \"apache_beam/runners/worker/operations.py\", line 589, in apache_beam.runners.worker.operations.DoOperation.start\n  File \"apache_beam/runners/worker/operations.py\", line 220, in apache_beam.runners.worker.operations.Operation.start\n  File \"apache_beam/runners/worker/operations.py\", line 224, in apache_beam.runners.worker.operations.Operation.start\n  File \"apache_beam/runners/worker/operations.py\", line 535, in apache_beam.runners.worker.operations.DoOperation.setup\n  File \"apache_beam/runners/worker/operations.py\", line 540, in apache_beam.runners.worker.operations.DoOperation.setup\n  File \"/usr/local/lib/python3.6/site-packages/apache_beam/internal/pickler.py\", line 265, in loads\n    return dill.loads(s)\n  File \"/usr/local/lib/python3.6/site-packages/dill/_dill.py\", line 317, in loads\n    return load(file, ignore)\n  File \"/usr/local/lib/python3.6/site-packages/dill/_dill.py\", line 305, in load\n    obj = pik.load()\n  File \"/usr/local/lib/python3.6/site-packages/dill/_dill.py\", line 577, in _load_type\n    return _reverse_typemap[name]\nKeyError: 'ClassType'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataflowRuntimeException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-bff066a77796>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                                     \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable_schema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                                     \u001b[0mwrite_disposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBigQueryDisposition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWRITE_TRUNCATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                                                     create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED)\n\u001b[0m",
      "\u001b[0;32m/home/.conda-env/env_nlp_text_class/lib/python3.6/site-packages/apache_beam/pipeline.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    425\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_until_finish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisitor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/.conda-env/env_nlp_text_class/lib/python3.6/site-packages/apache_beam/runners/dataflow/dataflow_runner.py\u001b[0m in \u001b[0;36mwait_until_finish\u001b[0;34m(self, duration)\u001b[0m\n\u001b[1;32m   1345\u001b[0m         raise DataflowRuntimeException(\n\u001b[1;32m   1346\u001b[0m             \u001b[0;34m'Dataflow pipeline failed. State: %s, Error:\\n%s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m             (self.state, getattr(self._runner, 'last_error_msg', None)), self)\n\u001b[0m\u001b[1;32m   1348\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataflowRuntimeException\u001b[0m: Dataflow pipeline failed. State: FAILED, Error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/apache_beam/internal/pickler.py\", line 261, in loads\n    return dill.loads(s)\n  File \"/usr/local/lib/python3.6/site-packages/dill/_dill.py\", line 317, in loads\n    return load(file, ignore)\n  File \"/usr/local/lib/python3.6/site-packages/dill/_dill.py\", line 305, in load\n    obj = pik.load()\n  File \"/usr/local/lib/python3.6/site-packages/dill/_dill.py\", line 577, in _load_type\n    return _reverse_typemap[name]\nKeyError: 'ClassType'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/dataflow_worker/batchworker.py\", line 649, in do_work\n    work_executor.execute()\n  File \"/usr/local/lib/python3.6/site-packages/dataflow_worker/executor.py\", line 176, in execute\n    op.start()\n  File \"apache_beam/runners/worker/operations.py\", line 587, in apache_beam.runners.worker.operations.DoOperation.start\n  File \"apache_beam/runners/worker/operations.py\", line 588, in apache_beam.runners.worker.operations.DoOperation.start\n  File \"apache_beam/runners/worker/operations.py\", line 589, in apache_beam.runners.worker.operations.DoOperation.start\n  File \"apache_beam/runners/worker/operations.py\", line 220, in apache_beam.runners.worker.operations.Operation.start\n  File \"apache_beam/runners/worker/operations.py\", line 224, in apache_beam.runners.worker.operations.Operation.start\n  File \"apache_beam/runners/worker/operations.py\", line 535, in apache_beam.runners.worker.operations.DoOperation.setup\n  File \"apache_beam/runners/worker/operations.py\", line 540, in apache_beam.runners.worker.operations.DoOperation.setup\n  File \"/usr/local/lib/python3.6/site-packages/apache_beam/internal/pickler.py\", line 265, in loads\n    return dill.loads(s)\n  File \"/usr/local/lib/python3.6/site-packages/dill/_dill.py\", line 317, in loads\n    return load(file, ignore)\n  File \"/usr/local/lib/python3.6/site-packages/dill/_dill.py\", line 305, in load\n    obj = pik.load()\n  File \"/usr/local/lib/python3.6/site-packages/dill/_dill.py\", line 577, in _load_type\n    return _reverse_typemap[name]\nKeyError: 'ClassType'\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline(options=pipeline_options) as p:\n",
    "    table = p                 | \"QueryTable\" >> beam.io.Read(beam.io.BigQuerySource(\n",
    "                                                    query=query,\n",
    "                                                    use_standard_sql=True))\n",
    "    clean_text = table        | \"Preprocessing\" >> beam.ParDo(CleanText())\n",
    "    clean_text                | \"WriteTable\" >> beam.io.WriteToBigQuery(\n",
    "                                                    new_table,\n",
    "                                                    schema=table_schema,\n",
    "                                                    write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE,\n",
    "                                                    create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env_nlp_text_class]",
   "language": "python",
   "name": "conda-env-env_nlp_text_class-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
