{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# NLP Preprocessing using Beam/Dataflow\n",
    "## Setup Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "workingdir=os.getcwd()\n",
    "#print(workingdir)\n",
    "d=[d for d in os.listdir(workingdir)]\n",
    "n=0\n",
    "while not set(['notebook']).issubset(set(d)):\n",
    "    workingdir=str(pathlib.Path(workingdir).parents[0])\n",
    "    #print(workingdir)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    d=[d for d in os.listdir(str(workingdir))]\n",
    "    n+=1\n",
    "    if n>5:\n",
    "        break\n",
    "sys.path.insert(0, workingdir)\n",
    "os.chdir(workingdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bs4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6a8e2436f518>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mapache_beam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline_options\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleCloudOptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0men_core_web_sm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mbs4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bs4'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import subprocess\n",
    "import datetime\n",
    "import subprocess, requests\n",
    "import apache_beam as beam\n",
    "from google.cloud import bigquery\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.options.pipeline_options import StandardOptions\n",
    "from apache_beam.options.pipeline_options import GoogleCloudOptions\n",
    "import en_core_web_sm\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Defined GCP env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# get all variables here\n",
    "os.environ['PROJECT_ID'] =  subprocess.run('gcloud config list project --format \"value(core.project)\"',\n",
    "                                             shell=True, check=True,\n",
    "                                             stdout=subprocess.PIPE).stdout.decode().replace('\\n', '').replace('\\r', '')\n",
    "\n",
    "os.environ['REGION'] = subprocess.run('gcloud config get-value compute/region  2> /dev/null',\n",
    "                                      shell=True, check=True,\n",
    "                                      stdout=subprocess.PIPE).stdout.decode().replace('\\n', '').replace('\\r', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env variable GOOGLE_APPLICATION_CREDENTIALS not defined!\n",
      "Env variable REQUESTS_CA_BUNDLE not defined!\n",
      "Env variable AXA_CA_CA_BUNDLE not defined!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tmp=os.environ['PROJECT_ID']\n",
    "except:\n",
    "    print('Env variable PROJECT not defined!') \n",
    "\n",
    "try:\n",
    "    tmp=os.environ['BUCKET_NAME']\n",
    "except:\n",
    "    print('Env variable BUCKET_NAME not defined!') \n",
    "\n",
    "try:\n",
    "    tmp=os.environ['REGION']\n",
    "except:\n",
    "    print('Env variable REGION not defined!') \n",
    "\n",
    "try:    \n",
    "    tmp=os.environ['GOOGLE_APPLICATION_CREDENTIALS']\n",
    "except:\n",
    "    print('Env variable GOOGLE_APPLICATION_CREDENTIALS not defined!') \n",
    "\n",
    "try:\n",
    "    tmp=os.environ['REQUESTS_CA_BUNDLE']\n",
    "except:\n",
    "    print('Env variable REQUESTS_CA_BUNDLE not defined!') \n",
    "\n",
    "try:\n",
    "    tmp=os.environ['AXA_CH_CA_BUNDLE']\n",
    "except:\n",
    "    print('Env variable AXA_CA_CA_BUNDLE not defined!') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Preprocessing using Beam/Dataflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        -RUNNER: \"DirectRunner\" or \"DataflowRunner\". Specfy to run the pipeline locally or on Google Cloud respectively.\n",
    "    Side-effects:\n",
    "        -Creates and executes dataflow pipeline.\n",
    "        See https://beam.apache.org/documentation/programming-guide/#creating-a-pipeline\n",
    "    \"\"\"\n",
    "    job_name = 'test-stackoverflow' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "    project = os.environ['PROJECT_ID']\n",
    "    region = os.environ['REGION']\n",
    "    output_dir = \"gs://{0}/stackoverflow/\".format(os.environ['BUCKET_NAME'])\n",
    "\n",
    "    # options    \n",
    "    options = PipelineOptions()\n",
    "    google_cloud_options = options.view_as(GoogleCloudOptions)\n",
    "    google_cloud_options.project =  project\n",
    "    google_cloud_options.job_name =  job_name\n",
    "    google_cloud_options.region = region\n",
    "    google_cloud_options.staging_location = os.path.join(output_dir, 'tmp', 'staging')\n",
    "    google_cloud_options.temp_location = os.path.join(output_dir, 'tmp')\n",
    "    # done by command line\n",
    "    options.view_as(StandardOptions).runner = 'DataflowRunner'\n",
    "\n",
    "    # instantantiate Pipeline object using PipelineOptions\n",
    "    print('Launching Dataflow job {} ... hang on'.format(job_name))\n",
    "    \n",
    "    print('Testing SpaCy ...')\n",
    "    en_core_web_sm.load()\n",
    "\n",
    "    p = beam.Pipeline(options=options)\n",
    "    output = p | 'Read from BigQuery' >> beam.io.Read(beam.io.BigQuerySource(\n",
    "        # query\n",
    "        query=create_query(),\n",
    "        # use standard SQL for the above query\n",
    "        use_standard_sql=True)\n",
    "        )\n",
    "    output | 'Write to BigQuery' >> beam.io.WriteToBigQuery(\n",
    "        # The table name is a required argument for the BigQuery\n",
    "        table='test_stackoverflow_beam',\n",
    "        dataset='test',\n",
    "        project=project,\n",
    "        # Here we use the JSON schema read in from a JSON file.\n",
    "        # Specifying the schema allows the API to create the table correctly if it does not yet exist.\n",
    "        schema=table_schema,\n",
    "        # Creates the table in BigQuery if it does not yet exist.\n",
    "        create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED,\n",
    "        # Deletes all data in the BigQuery table before writing.\n",
    "        write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE)\n",
    "        # not needed, from with clause\n",
    "\n",
    "    if options.view_as(StandardOptions).runner == 'DataflowRunner':\n",
    "        print('DataflowRunner')\n",
    "        p.run()\n",
    "    else:\n",
    "        print('Default: DirectRunner')\n",
    "        result = p.run()\n",
    "        result.wait_until_finish()\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Apache Beam and GCP Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Creating a DoFn Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class Split(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        self.id, self.title, self.body, self.tags = element.split(\",\")\n",
    "\n",
    "        return [{\n",
    "            'id': self.id,\n",
    "            'title': self.title,\n",
    "            'body': self.body,\n",
    "            'tags': self.tags\n",
    "        }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class CleanText(beam.DoFn):\n",
    "    def __init__(self):\n",
    "        self.spacy = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "        \n",
    "    def __decode_html(self, input_str: str) -> str:\n",
    "        self.soup = bs4.BeautifulSoup(input_str, 'html.parser')\n",
    "        self.output = self.soup.text\n",
    "        return self.output\n",
    "\n",
    "    def __nlp(self, input_str: str) -> list:\n",
    "        self.doc = self.spacy(input_str)\n",
    "        self.stopwords = list(string.punctuation + string.digits) + ['-pron-']\n",
    "        self.output = [token.lemma_.lower() for token in self.doc if not token.is_stop \n",
    "                  and token.lemma_.lower() not in self.stopwords]\n",
    "        return self.output\n",
    "\n",
    "    def __split_tags(self, tags: str) -> list:\n",
    "        return tags.split('|')\n",
    "\n",
    "    def process(self, element):\n",
    "        self.title_array = self.__nlp(element['title'])\n",
    "        self.body_decoded = self.__decode_html(element['tags'])\n",
    "        self.body_array = self.__nlp(self.body_decoded)\n",
    "        self.tag_array = self.__split_tags(element['tags'])\n",
    "        \n",
    "        return [{'id': int(element['id']), \n",
    "                 'title': self.title_array, \n",
    "                 'body': self.body_array, \n",
    "                 'tags': self.tag_array}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Local Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "local_file = 'data/beam_test.csv'\n",
    "if os.path.exists('data/beam_output.txt'):\n",
    "    os.remove('data/beam_output.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "with beam.Pipeline(argv=sys.argv) as p:\n",
    "    file = p                  | \"ReadLocalFile\" >> beam.io.ReadFromText(local_file)\n",
    "    table = file              | \"CreateDictionary\"  >> beam.ParDo(Split())\n",
    "    clean_text = table        | \"ProcessFields\" >> beam.ParDo(CleanText())\n",
    "    clean_text                | \"WriteLocalFile\" >> beam.io.WriteToText('data/beam_output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## GCP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "query = '''SELECT\n",
    "  id,\n",
    "  title,\n",
    "  body,\n",
    "  tags\n",
    "FROM\n",
    "  bigquery-public-data:stackoverflow.stackoverflow_posts'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "table_schema = {'fields': [\n",
    "    {'name': 'id', 'type': 'NUMERIC', 'mode': 'REQUIRED'},\n",
    "    {'name': 'title', 'type': 'ARRAY', 'mode': 'NULLABLE'},\n",
    "    {'name': 'body', 'type': 'ARRAY', 'mode': 'NULLABLE'},\n",
    "    {'name': 'tags', 'type': 'ARRAY', 'mode': 'NULLABLE'},\n",
    "]}\n",
    "new_table = 'nlp_text_classification.stackoverflow_posts_preprocessed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "with beam.Pipeline(options=pipeline_options) as p:\n",
    "    table = p                 | \"QueryTable\" >> beam.io.Read(beam.io.BigQuerySource(query))\n",
    "    clean_text = table        | \"ProcessFields\" >> beam.ParDo(CleanText())\n",
    "    clean_text                | \"WriteTable\" >> beam.io.WriteToBigQuery(\n",
    "                                                    new_table,\n",
    "                                                    schema=table_schema,\n",
    "                                                    write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE,\n",
    "                                                    create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env_nlp_text_class]",
   "language": "python",
   "name": "conda-env-env_nlp_text_class-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
