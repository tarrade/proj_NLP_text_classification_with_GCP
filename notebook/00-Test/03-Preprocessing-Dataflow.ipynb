{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": false
   },
   "source": [
    "# Preprocessing using Beam/Dataflow\n",
    "## Setup Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false",
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "workingdir=os.getcwd()\n",
    "#print(workingdir)\n",
    "d=[d for d in os.listdir(workingdir)]\n",
    "n=0\n",
    "while not set(['notebook']).issubset(set(d)):\n",
    "    workingdir=str(pathlib.Path(workingdir).parents[0])\n",
    "    #print(workingdir)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    d=[d for d in os.listdir(str(workingdir))]\n",
    "    n+=1\n",
    "    if n>5:\n",
    "        break\n",
    "sys.path.insert(0, workingdir)\n",
    "os.chdir(workingdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import subprocess\n",
    "import datetime\n",
    "import subprocess, requests\n",
    "import apache_beam as beam\n",
    "from google.cloud import bigquery\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.options.pipeline_options import StandardOptions\n",
    "from apache_beam.options.pipeline_options import GoogleCloudOptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Defined GCP env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all variables here\n",
    "os.environ['PROJECT_ID'] =  subprocess.run('gcloud config list project --format \"value(core.project)\"',\n",
    "                                             shell=True, check=True,\n",
    "                                             stdout=subprocess.PIPE).stdout.decode().replace('\\n', '').replace('\\r', '')\n",
    "\n",
    "os.environ['REGION'] = subprocess.run('gcloud config get-value compute/region  2> /dev/null',\n",
    "                                      shell=True, check=True,\n",
    "                                      stdout=subprocess.PIPE).stdout.decode().replace('\\n', '').replace('\\r', '')\n",
    "# bucket storage name\n",
    "os.environ['BUCKET_NAME']='axa-ch-machine-learning-poc-dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env variable GOOGLE_APPLICATION_CREDENTIALS not defined!\n",
      "Env variable REQUESTS_CA_BUNDLE not defined!\n",
      "Env variable AXA_CA_CA_BUNDLE not defined!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tmp=os.environ['PROJECT_ID']\n",
    "except:\n",
    "    print('Env variable PROJECT not defined!') \n",
    "\n",
    "try:\n",
    "    tmp=os.environ['BUCKET_NAME']\n",
    "except:\n",
    "    print('Env variable BUCKET_NAME not defined!') \n",
    "\n",
    "try:\n",
    "    tmp=os.environ['REGION']\n",
    "except:\n",
    "    print('Env variable REGION not defined!') \n",
    "\n",
    "try:    \n",
    "    tmp=os.environ['GOOGLE_APPLICATION_CREDENTIALS']\n",
    "except:\n",
    "    print('Env variable GOOGLE_APPLICATION_CREDENTIALS not defined!') \n",
    "\n",
    "try:\n",
    "    tmp=os.environ['REQUESTS_CA_BUNDLE']\n",
    "except:\n",
    "    print('Env variable REQUESTS_CA_BUNDLE not defined!') \n",
    "\n",
    "try:\n",
    "    tmp=os.environ['AXA_CH_CA_BUNDLE']\n",
    "except:\n",
    "    print('Env variable AXA_CA_CA_BUNDLE not defined!') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Preprocessing using Beam/Dataflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Define a query to get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define query table\n",
    "def create_query():\n",
    "    query = \"\"\"\n",
    "    SELECT\n",
    "    *\n",
    "    FROM\n",
    "    `bigquery-public-data.stackoverflow.tags`\n",
    "    LIMIT 100\n",
    "    \"\"\"\n",
    "\n",
    "    return query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the schema of the input table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"creationTime\": \"1477491432274\", \n",
      "  \"etag\": \"MA4KCkNQ6uZukuWZs/YFNQ==\", \n",
      "  \"id\": \"bigquery-public-data:stackoverflow.tags\", \n",
      "  \"kind\": \"bigquery#table\", \n",
      "  \"lastModifiedTime\": \"1569811976063\", \n",
      "  \"location\": \"US\", \n",
      "  \"numBytes\": \"2284573\", \n",
      "  \"numLongTermBytes\": \"0\", \n",
      "  \"numRows\": \"55665\", \n",
      "  \"schema\": {\n",
      "    \"fields\": [\n",
      "      {\n",
      "        \"mode\": \"NULLABLE\", \n",
      "        \"name\": \"id\", \n",
      "        \"type\": \"INTEGER\"\n",
      "      }, \n",
      "      {\n",
      "        \"mode\": \"NULLABLE\", \n",
      "        \"name\": \"tag_name\", \n",
      "        \"type\": \"STRING\"\n",
      "      }, \n",
      "      {\n",
      "        \"mode\": \"NULLABLE\", \n",
      "        \"name\": \"count\", \n",
      "        \"type\": \"INTEGER\"\n",
      "      }, \n",
      "      {\n",
      "        \"mode\": \"NULLABLE\", \n",
      "        \"name\": \"excerpt_post_id\", \n",
      "        \"type\": \"INTEGER\"\n",
      "      }, \n",
      "      {\n",
      "        \"mode\": \"NULLABLE\", \n",
      "        \"name\": \"wiki_post_id\", \n",
      "        \"type\": \"INTEGER\"\n",
      "      }\n",
      "    ]\n",
      "  }, \n",
      "  \"selfLink\": \"https://bigquery.googleapis.com/bigquery/v2/projects/bigquery-public-data/datasets/stackoverflow/tables/tags\", \n",
      "  \"tableReference\": {\n",
      "    \"datasetId\": \"stackoverflow\", \n",
      "    \"projectId\": \"bigquery-public-data\", \n",
      "    \"tableId\": \"tags\"\n",
      "  }, \n",
      "  \"type\": \"TABLE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# getting schema\n",
    "! bq show --format=prettyjson bigquery-public-data:stackoverflow.tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "table_schema = {\n",
    "    'fields': [\n",
    "        {\n",
    "            'mode': 'NULLABLE',\n",
    "            'name': 'id',\n",
    "            'type': 'INTEGER'\n",
    "        },\n",
    "        {\n",
    "            'mode': 'NULLABLE',\n",
    "            'name': 'tag_name',\n",
    "            'type': 'STRING'\n",
    "        },\n",
    "        {\n",
    "            'mode': 'NULLABLE',\n",
    "            'name': 'count',\n",
    "            'type': 'INTEGER'\n",
    "        },\n",
    "        {\n",
    "            'mode': 'NULLABLE',\n",
    "            'name': 'excerpt_post_id',\n",
    "            'type': 'INTEGER'\n",
    "        },\n",
    "        {\n",
    "            'mode': 'NULLABLE',\n",
    "            'name': 'wiki_post_id',\n",
    "            'type': 'INTEGER'\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        -RUNNER: \"DirectRunner\" or \"DataflowRunner\". Specfy to run the pipeline locally or on Google Cloud respectively.\n",
    "    Side-effects:\n",
    "        -Creates and executes dataflow pipeline.\n",
    "        See https://beam.apache.org/documentation/programming-guide/#creating-a-pipeline\n",
    "    \"\"\"\n",
    "    job_name = 'test-stackoverflow' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "    project = os.environ['PROJECT_ID']\n",
    "    region = os.environ['REGION']\n",
    "    output_dir = \"gs://{0}/stackoverflow/\".format(os.environ['BUCKET_NAME'])\n",
    "\n",
    "    # options\n",
    "    options = PipelineOptions()\n",
    "    google_cloud_options = options.view_as(GoogleCloudOptions)\n",
    "    google_cloud_options.project =  project\n",
    "    google_cloud_options.job_name =  job_name\n",
    "    google_cloud_options.region = region\n",
    "    google_cloud_options.staging_location = os.path.join(output_dir, 'tmp', 'staging')\n",
    "    google_cloud_options.temp_location = os.path.join(output_dir, 'tmp')\n",
    "    # done by command line\n",
    "    #options.view_as(StandardOptions).runner = 'DataflowRunner'\n",
    "\n",
    "    # instantantiate Pipeline object using PipelineOptions\n",
    "    print('Launching Dataflow job {} ... hang on'.format(job_name))\n",
    "\n",
    "    p = beam.Pipeline(options=options)\n",
    "    output = p | 'Read from BigQuery' >> beam.io.Read(beam.io.BigQuerySource(\n",
    "        # query\n",
    "        query=create_query(),\n",
    "        # use standard SQL for the above query\n",
    "        use_standard_sql=True)\n",
    "        )\n",
    "    output | 'Write to BigQuery' >> beam.io.WriteToBigQuery(\n",
    "        # The table name is a required argument for the BigQuery\n",
    "        table='test_stackoverflow_beam',\n",
    "        dataset='test',\n",
    "        project=project,\n",
    "        # Here we use the JSON schema read in from a JSON file.\n",
    "        # Specifying the schema allows the API to create the table correctly if it does not yet exist.\n",
    "        schema=table_schema,\n",
    "        # Creates the table in BigQuery if it does not yet exist.\n",
    "        create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED,\n",
    "        # Deletes all data in the BigQuery table before writing.\n",
    "        write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE)\n",
    "        # not needed, from with clause\n",
    "\n",
    "    if options.view_as(StandardOptions).runner == 'DataflowRunner':\n",
    "        print('DataflowRunner')\n",
    "        p.run()\n",
    "    else:\n",
    "        print('Default: DirectRunner')\n",
    "        result = p.run()\n",
    "        result.wait_until_finish()\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Missing pipeline option (runner). Executing pipeline using the default runner: DirectRunner.\n",
      "DEBUG:root:Unhandled type_constraint: Union[]\n",
      "DEBUG:root:Unhandled type_constraint: Union[]\n",
      "DEBUG:root:Unhandled type_constraint: Any\n",
      "INFO:root:Running pipeline with DirectRunner.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main process ...\n",
      "Launching Dataflow job test-stackoverflow-191023-075445 ... hang on\n",
      "Default: DirectRunner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using location 'US' from table <TableReference\n",
      " datasetId: 'stackoverflow'\n",
      " projectId: 'bigquery-public-data'\n",
      " tableId: 'tags'> referenced by query \n",
      "    SELECT\n",
      "    *\n",
      "    FROM\n",
      "    `bigquery-public-data.stackoverflow.tags`\n",
      "    LIMIT 100\n",
      "    \n",
      "WARNING:root:Dataset axa-ch-machine-learning-dev:temp_dataset_4b273308ba7d4ab8920b6103b3005249 does not exist so we will create it as temporary with location=US\n",
      "DEBUG:root:Creating or getting table <TableReference\n",
      " datasetId: 'test'\n",
      " projectId: 'axa-ch-machine-learning-dev'\n",
      " tableId: 'test_stackoverflow_beam'> with schema {'fields': [{'mode': 'NULLABLE', 'name': 'id', 'type': 'INTEGER'}, {'mode': 'NULLABLE', 'name': 'tag_name', 'type': 'STRING'}, {'mode': 'NULLABLE', 'name': 'count', 'type': 'INTEGER'}, {'mode': 'NULLABLE', 'name': 'excerpt_post_id', 'type': 'INTEGER'}, {'mode': 'NULLABLE', 'name': 'wiki_post_id', 'type': 'INTEGER'}]}.\n",
      "DEBUG:root:Created the table with id test_stackoverflow_beam\n",
      "INFO:root:Created table axa-ch-machine-learning-dev.test.test_stackoverflow_beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'tag_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'count'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'excerpt_post_id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'wiki_post_id'\n",
      " type: 'INTEGER'>]>. Result: <Table\n",
      " creationTime: 1571817293074\n",
      " etag: 'Yv9szGv1cX4TDjdyD8JOVw=='\n",
      " id: 'axa-ch-machine-learning-dev:test.test_stackoverflow_beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1571817293117\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'tag_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'count'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'excerpt_post_id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'wiki_post_id'\n",
      " type: 'INTEGER'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/axa-ch-machine-learning-dev/datasets/test/tables/test_stackoverflow_beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'test'\n",
      " projectId: 'axa-ch-machine-learning-dev'\n",
      " tableId: 'test_stackoverflow_beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:root:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n",
      "DEBUG:root:Attempting to flush to all destinations. Total buffered: 100\n",
      "DEBUG:root:Flushing data to axa-ch-machine-learning-dev:test.test_stackoverflow_beam. Total 100 rows.\n",
      "DEBUG:root:Passed: True. Errors are []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "    print('Starting main process ...')\n",
    "    preprocess()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nlp_text_class",
   "language": "python",
   "name": "env_nlp_text_class"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
